{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#### Importing Libraries","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statistics import mean\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport cv2\n\nimport timm\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import StepLR\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"#### Data Analysis\n* concetto_CDT contains images of hand-drawn clock\n* train_csv contain the corrsponding image id and their labels\n* test_csv contain the images which needs to be predicted","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/concetto22/train.csv')\ntest = pd.read_csv('../input/concetto22/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function adds an extra column having the path of the images\ndef append_path(df):\n    target_str = []\n    for i in range(len(df)):\n        target_str.append(str(df['id'][i]))\n    for i in range(len(df)):\n        target_str[i] = target_str[i].replace('.0', '.tif') \n        target_str[i] = '/kaggle/input/concetto22/concetto_CDT/concetto_CDT/'+target_str[i]\n    df['path'] = target_str\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = append_path(train)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = append_path(test)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data visualization","metadata":{}},{"cell_type":"code","source":"plt.imshow(cv2.imread(train['path'][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Splitting the train data into train and val set","metadata":{}},{"cell_type":"code","source":"X = train.drop(['tar'], axis=1)\ny = train['tar']\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42, stratify = y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.merge(x_train, y_train, right_index=True, left_index=True)\nval_data = pd.merge(x_val, y_val, right_index=True, left_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining a configuration\n\nclass CFG:\n    model_name = 'efficientnet_b2'\n    target_size = 6\n    size = 264\n    batch_size = 12\n    epochs = 15\n    num_workers = 2\n    lr = 1e-3\n    weight_decay = 0\n    train = True\n    target_col = 'tar'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dataset creation \nCreating a custom dataset for training and test data which takes path of images, transforms it and converts the image to tensors for further processing.","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['path'].values\n        self.labels = df['tar'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = file_name\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        label = torch.tensor(self.labels[idx]).long()\n        return image, label\n    \n\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['path'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = file_name\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformation","metadata":{}},{"cell_type":"markdown","source":"#### Augmentation\nApplying some necessary augmentations like resizing the image to the size accepted by model, Normalizing the tensors.\nAlbumentations like RandomResizedCrop and HorizontalFlip are used to augment the dataset.\nFind more albumentations [here](https://github.com/pytorch/vision/blob/main/torchvision/transforms/transforms.py)","metadata":{}},{"cell_type":"code","source":"# Transforms\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.RandomResizedCrop(CFG.size, CFG.size),\n            A.HorizontalFlip(p=0.5),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CustomNet(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n        #print(self.model.default_cfg[\"classifier\"])\n        n_features = self.model.classifier.in_features #either fc or classifier , check using above line\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CustomNet(model_name=CFG.model_name, pretrained=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss Function\nThe loss function used, here [CrossEntropyLoss.](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)","metadata":{}},{"cell_type":"code","source":"def get_criterion():\n    criterion = nn.CrossEntropyLoss()\n    return criterion","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer","metadata":{}},{"cell_type":"code","source":"def get_optimizer(model):\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    return optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scheduler\nIt is used for adjusting the learning rate(LR decay) between epochs as the training progresses. Read about more schedulers [here](https://pytorch.org/docs/stable/optim.html#)","metadata":{}},{"cell_type":"code","source":"def get_scheduler(optimizer):\n    scheduler = StepLR(optimizer, step_size=2, gamma=0.1, verbose=True)\n    return scheduler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utility Functions","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train() # switch to training mode\n    running_loss = 0\n    count = 0\n    for (images, labels) in tqdm(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        y_preds = model(images)\n        \n        loss = criterion(y_preds, labels)\n        running_loss += loss.item()*labels.shape[0]\n        count += 1\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    return running_loss/count\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    model.eval() # switch to evaluation mode\n    preds = []\n    running_loss = 0\n    count = 0\n    \n    for (images, labels) in tqdm(valid_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        running_loss += loss.item()*labels.shape[0]\n        count += 1\n        # record accuracy\n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    \n    return (running_loss/count), predictions\n\n\ndef test_fun(test_loader, model, device):\n    model.eval()\n    preds = []\n    test_df = pd.DataFrame()\n    for step, (images) in enumerate(test_loader):\n        images = images.to(device)\n        with torch.no_grad():\n            y_preds = model(images)\n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    pred = predictions.argmax(1)\n    return pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train loop","metadata":{}},{"cell_type":"code","source":"# Train loop\ndef train_loop(train_data, valid_data):\n    \n    # create dataset\n    train_dataset = TrainDataset(train_data, transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_data, transform=get_transforms(data='valid'))\n\n    # create dataloader\n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    # create model and transfer to device\n    model = CustomNet(CFG.model_name, pretrained=True)\n    model.to(device)\n    \n    # select optimizer, scheduler and criterion\n    optimizer = get_optimizer(model)\n    scheduler = get_scheduler(optimizer)\n    criterion = get_criterion()\n\n    best_score = -1.0\n    best_loss = np.inf\n    \n    # start training\n    for epoch in range(CFG.epochs):\n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n        # validation\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n#         valid_labels = valid_folds[CFG.target_col].values\n        valid_labels = valid_data['tar']\n        \n        scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds.argmax(1))\n        print(\"score: \", score)\n\n        # code for saving the best model\n        if score > best_score:\n            print('Score Improved')\n            best_score = score\n            print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f}')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds,\n                        'optimizer': optimizer.state_dict(),\n                        'scheduler': scheduler.state_dict()},\n                        './'+f'{CFG.model_name}_best.pth')\n    \n    check_point = torch.load('./'+f'{CFG.model_name}_best.pth')\n    valid_data['preds'] = check_point['preds'].argmax(1)\n\n    return valid_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# main\ndef main():\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n    \n    if CFG.train: \n        # train\n        df = train_loop(train_data, val_data)\n        get_result(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, \n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\ncheck_point = torch.load('./'+f'{CFG.model_name}_best.pth')\nmodel = CustomNet(CFG.model_name, pretrained=True)\nmodel.to(device)\nmodel.load_state_dict(check_point['model'])\npred = test_fun(test_loader, model, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['tar'] = pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = test.drop(['path'], axis=1)\nsubmission_df.to_csv(\"solution.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now click on the \"Submit\" button to submit the notebook\n### NOTE: We expect everyone to generate such notebooks for your final submission. Only the teams with notebook submitted against their final submission will be considered for prize money!","metadata":{}},{"cell_type":"markdown","source":"### Things to try next:\n* Try different architectures, optimizers, loss functions etc.\n* Think of ways of tackling data imbalance problem.\n* Try different image size\n* Try Ensembling methods.\n* Apply semi supervised learning.","metadata":{}},{"cell_type":"markdown","source":"### PS: This competition is hosted to promote learning. So we request you to publish your baseline models via Kaggle kernels and discuss on the discussion tab to help others learn. Thanks!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}